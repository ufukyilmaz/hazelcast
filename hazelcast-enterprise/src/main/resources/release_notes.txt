
In this Release Notes document, you will find the new features, enhancements and fixes of the Hazelcast 3.9 release.
The numbers in the square brackets refer to the issue number in Hazelcastâ€™s GitHub repository. You can reach
to the full descriptions of the issues at https://github.com/hazelcast/hazelcast/issues/<issue number>.

1. New Features

The following are the new features introduced with 3.9 release.

- WAN Replication on Amazon EC2: With this new feature, you can run multiple clusters within EC2 environment without manually configuring IP addresses and use Hazelcast's WAN replication to keep them in sync.
- Dynamic Creation of Distributed Objects Configuration: You can perform on the fly configuration of your distributed objects.

2. Enhancements

The following are the enhancements introduced with 3.9 release.

- Dynamic Role Update: You can update security permissions in a running cluster without the performing a rolling restart.
- Search Indexes in High-Density Memory Store: Now, sorted and unsorted indexes for High-Density Memory Store are supported.
- Members-only License Installation: Licenses are installed only at the member side, not the client side.
- Client Support for User Code Deployment: You can now perform dynamic class loading from Hazelcast clients too.
- Client Statistics in Management Center: Hazelcast Management Center shows client statistics.
- OpenSSL Integration: OpenSSL is integrated into Hazelcast.
- Filtering and Projection Support for MapPartitionIterator: Purpose of this enhancement is to allow Hazelcast Jet to perform filtering and projections on IMap.
- Fine-Grained Anti-Entropy Mechanism: Allows to detect inconsistencies for each data structure in a single partition and replicate only the specific fragment of it instead of the whole partition.
- Offloadable and Readonly entry processors: These interfaces introduces in order to significantly improve entry processors' throughput.
- Gigantic Cache Migration Enhancements: It enables manual control on the partition migrations. Partitions can be migrated/replicated in small fragments. Please refer to the hazelcast.partition.migration.fragments.enabled system property and NO_MIGRATION cluster state.
- Keeping JCache Implementation Updated: Hazelcast JCache implementation is updated for JSR 1.1 compliance when it is released.
- Storing Near Cache Keys by Reference: This enhancement provides a functionality to skip the serialization of keys for Near Caches to improve the performance of the Near Caches.
- Client Connection Strategy Enhancements: Allows lazy initiation for Hazelcast Clients.
- All Statistics as JMX Beans: All statistics shown on the Hazelcast Management Center are now available as JMX beans.
- Default Group Password and Symmetric Encryption Default Credentials Policy: Hazelcast requires the default group password and default symmetric encryption password/salt to be changed.
- Hazelcast Consistency Model Documentation: We added a new section explaining the full picture of Hazelcast's consistency model.

The following are the other improvements performed to solve the enhancement issues opened by the Hazelcast customers/team.

- The attribute override-java-serialization should be added to the element global-serializer in hazelcast-client-config.xsd. [#10449]
- Hazelcast should have a method like gerOrCreateHazelcastInstance() to detect a default configuration file and either create an instance or get an existing one. [#10007]
- Allow binding any port without using the method setPortAutoIncrement() and specifying the port count. [#9775]
- Consistent interface for IMap and TransactionalMap is needed. [#8729]
- Hazelcast instance's name should be added as a prefix to the name of the threads managed by Hazelcast. [#8542]
- When back pressure is enabled members always use back-off and clients always throws HazelcastOverloadedException. This is not consistent and the behavior should be configurable on both members and clients. [#8533]
- For OperationService, the contention on the counters should be reduced. [#4925]
- Some of the properties mentioned in GroupProperties are not used anymore, it should be cleaned up. [#4505]
- When a grid member is configured to use port 0, it should be handled properly. [#2506]


3. Fixes

The following are the issues solved for Hazelcast 3.9-EA release.

- The system property hazelcast.cache.invalidation.batchfrequency.seconds does not work for IMap. [#10743]
- When a Java application is run with Hazelcast 3.8.2 within Docker, and after switching from openjdk:8u121-jre-alpine to openjdk:8u131-jre-alpine, IllegalArgumentException is thrown during cluster bootstrap. [#10704]
- Scheduled task remains cancelled after migration. [#10603]
- New cache eviction is populated among nodes very slowly. [#10470]
- WAN backup events are published twice. The publishWanReplicationEventBackups method is called in the run and afterRun method in the PartitionWideEntryBackupOperation. Elsewhere it is only called in afterRun. This needs to be checked but possibly the fix is just to remove the call in run. [#10457]
- Source parameter is null on JCache.loadAll() call. [#10328]
- TcpIpJoiner throws the exceptionConcurrentModificationException: null. [#10207]
- It seems like the Near Cache statistics seem to be off-by-one for at least the ownedEntryCount. Sometimes the ownedEntryMemoryCost seems to be affected as well. [#10193]
- Setting up a Hazelcast listener in a Spring configuration format does not seem to work when using the class property of hz:listener. [#10154]
- Test coverage for NearCacheClientCacheProxy should be increased. [#10127]
- Hazelcast XML configuration does not allow RANDOM eviction as an eviction policy. [#10053]
- There is a race condition in TestClientRegistry where the tests are calling blockFrom and blockTo before any connection was made (via createSocketConnection). This causes NullPointerException in those block methods. [#10021]
- When health check is enabled, the user can send a garbage request like http://<your member's host IP>:5701/hazelcast/healthqqq and it returns a correct response. [#9967]
- Durable Executor Service re-executes the completed tasks in case of a member failure. [#9965]
- The option cache-local-entries is not supported at the client side Near Cache configuration. [#9712]
- Latest member-list may not be received when FinalizeJoinOperation invocation timeouts. [#9501]
- Cluster member-list update operations are not ordered, new member addition and removal operations can get reordered on receiving/processing side. Also periodic member-list publish operation has no order with other member adding/removing operations. That can cause having different member lists on different members. [#9486]
- Backup is lost if maxIdle property is used. [#9153]
- Heartbeat only removes a member if it is related to the master member. [#5253]
- Rolling Upgrade: 3.9 member cannot join to 3.8 cluster. [#1492]
- `ObjectNamespace` cannot be serialized compatibly. [#1471]
- When serializing a `Versioned` `DataSerializable`, `Input/Output.getVersion()` returns `UNKNOWN` when a non-versioned field is serialized inside outer `Versioned`. [#1369]

4. Behavioral Changes

- Maximum timeout of heartbeat for a member to assume it is dead was 300 seconds. Starting with Hazelcast 3.9, it is reduced to 60 seconds. Also, starting with Hazelcast 3.9, maximum timeout of master confirmation from other members is reduced to 150 seconds from 450 seconds.

- Starting with Hazelcast 3.9, the format of member list shown in the logs is changed. Before Hazelcast 3.9, it was like the following:

Members [3] {
    Member [127.0.0.1]:5701 - c1ccc8d4-a549-4bff-bf46-9213e14a9fd2 this
    Member [127.0.0.1]:5702 - 33a82dbf-85d6-4780-b9cf-e47d42fb89d4
    Member [127.0.0.1]:5703 - 813ec82f-9d9e-4712-bae1-6c95b32d6d7d
}
Starting with Hazelcast 3.9, it is shown as follows:

Members {size:3, ver:3} [
  Member [127.0.0.1]:5701 - e40081de-056a-4ae5-8ffe-632caf8a6cf1 this
  Member [127.0.0.1]:5702 - 93e82109-16bf-4b16-9c87-f4a6d0873080
  Member [127.0.0.1]:5703 - 06fb4e61-9757-443b-a19f-7af1f3966f30
]
Here, you can see the size of your cluster (size) and member list version (ver). The member list version will be incremented when changes happen to the cluster, e.g., a member leaving from or joining to the cluster.

You can set the system property hazelcast.legacy.memberlist.format.enabled to true if you want to see the member list in its old format.
